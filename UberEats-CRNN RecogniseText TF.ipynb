{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UberEats - CRNN Text Recognition using TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import string\n",
    "from IPython.core import display\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "modelfilepath=\"models/best_model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character List:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\n"
     ]
    }
   ],
   "source": [
    "# Global Variables\n",
    "char_list = string.ascii_letters + string.digits\n",
    "print(\"Character List: \", char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micdsouz/wrkdir/ctpn/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# load the saved best model weights\n",
    "act_model = load_model(modelfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(imgpath):\n",
    "    print(\"Preprocessing image: \", imgpath)\n",
    "    display.display(display.Image(imgpath))\n",
    "    # read input image and convert to grayscale\n",
    "    img = cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2GRAY)\n",
    "    # convert each image of shape (32, 128, 1)\n",
    "    w, h = img.shape\n",
    "\n",
    "    # Process the images to bring them to scale\n",
    "    if w < 32:\n",
    "        add_zeros = np.ones((32-w, h))*255\n",
    "        img = np.concatenate((img, add_zeros))\n",
    "    # endif\n",
    "                       \n",
    "    if h < 128:\n",
    "        add_zeros = np.ones((32, 128-h))*255\n",
    "        img = np.concatenate((img, add_zeros), axis=1)\n",
    "    # endif    \n",
    "\n",
    "    img = np.expand_dims(img , axis = 2)\n",
    "                       \n",
    "    # Normalise the image\n",
    "    img = img/255.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sample = \"data/test/1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing image:  data/test/1.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(32, 128, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_image = preprocess_img(image_sample)\n",
    "preprocessed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 128, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocessed_image.reshape(1,32,128,1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outputs on validation images\n",
    "prediction = act_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted text = Bastoncilo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(char_list[int(p)], end = '')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctpn",
   "language": "python",
   "name": "ctpn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
